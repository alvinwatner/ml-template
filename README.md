# Introduction
In many Machine Learning (ML) communities, I have observed that many people are often struggling with different problems which are actually rooted on the exact same problem. The main issue is not “how to perform this step?” but rather than “which step should be performed first?”. In addition, the existing tutorials and articles mostly cover different techniques to perform a specific step (for e.g., how to deal with imbalance class or skewed continuous features). Therefore, I proposed a template that provides a general workflow to guide the process of developing ML models for classification and regression tasks on tabular data in the Kaggle Competition setting. To my knowledge, this is the first notebook that is dedicated to establish the exact same workflow for various ML tasks.

# Previous Works
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

# Proposed Solution
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

### Tasks and Dataset 

- [X] Binary Classification 
   
   * [Insomnia](https://www.kaggle.com/competitions/idao-2022-bootcamp-insomnia/overview)
   * [Titanic](https://www.kaggle.com/c/titanic)
   * [Diabetes](https://www.kaggle.com/datasets/kandij/diabetes-dataset)
- [X] Multi-class Classification
    * [Body Performance](https://www.kaggle.com/datasets/kukuroo3/body-performance-data)
    * [Ghouls, Goblins, and Ghosts... Boo!](https://www.kaggle.com/competitions/ghouls-goblins-and-ghosts-boo/overview)
- [ ] Single-output Regression
    * [Car price](https://www.kaggle.com/datasets/hellbuoy/car-price-prediction)
    * [Second Hand Car price](https://www.kaggle.com/datasets/mayankpatel14/second-hand-used-cars-data-set-linear-regression)
    * [Concrete Compressive Strength](https://www.kaggle.com/datasets/maajdl/yeh-concret-data)
- [ ] Multi-output Regression
    * [Possum](https://www.kaggle.com/datasets/abrambeyer/openintro-possum)




 > ### The boring questions :/ 
> 1) Why do we perform categorical feature encoding before data splitting?
> 2) Why do we perform feature transformation after data > splitting?
> 3) Why do we deal with outliers first before imputing missing values?
> 4) Why do we perform oversampling and undersampling after feature transformation and feature encoding?
